CONTAINER ORCHESTRATION w KUBERNETES

deploy more complex apps under microservices architecture (multiple containers)
- high availability/no downtime
- scalability/high performance
- disaster recovery/backup and restore

K8s components:
1. Node - physical or virtual server
2. Pod - abstraction over container (smallest unit of K8s)
  each Pod gets its own IP address
  Pods are ephemeral (can die easily), IP address recreated as new Pod recreated
3. Service - permanent IP address that can be attached to Pod, also acts as load balancer between Pods
4. Ingress - forwarding from request to Service (allows display dns in url)
5. ConfigMap - external config of app
6. Secret - used to store secret data, base64 encoded
7. Volumes - persists data
8. Deployment - blueprint for Pods (number of replicas) - abstraction layer over Pods
10. StatefulSet - Deployment for stateful apps or DBs
11. Replicaset - abstraction layer between pods and deployments (manages replicas of pods)

K8s architecture:
  each worker node has mutliple pods in it
  3 processes must be installed on every node:
    - container runtime (docker, container d ...)
    - Kubelet - interacts with both container and node
    - Kube proxy - forwards request from pods
  master nodes have 4 processes running:
    - api server - gateway & auth
    - scheduler - schedules pods across nodes
    - controller manager - detects state changes (eg crashing pods) and tries recover cluster state
    - etcd - key value store of cluster state
  prod cluster setup: multiple master and worker nodes

Minikube - for testing cluster setup on local: master & worker processes run on 1 node
  
Kubectl - cmd line tool for K8s: talk to API server
  kubectl get nodes
  kubectl get pod
  kubectl get pod -o wide (display more info for pod like IP address)
  kubectl get deployment
  kubectl get services
  kubectl create deployment NAME --image=image
  kubectl edit deployment NAME
  kubectl logs NAME
  kubectl describe pod NAME
  kubectl exec -it NAME -- bin/bash
  kubctl delete deployment NAME
  kubectl apply -f FILENAME (takes config file and exec what is in file, can be used to create edit delete)

K8s config file
  3 parts:
    1. metadata
    2. specification
    3. status (auto generated by K8s that checks diff to update state if applicable)
  store file w code
  pod has own config inside config
  connect deployment to pods, deployment to services using labels & selectors
  need to config ports for services (targetPort = container port that service wants to connect to)

Namespaces - organise resources
4 namespaces by default:
  - kube-system - system processes (DONT modify)
  - kube-public - configmap containing cluster info
  - kube-node-lease - heartbeat of nodes for availability
  - default - resources you create if haven't specified custom namespace
create namespaces options:
  1. kubectl create namespace <NAME>
  kubectl get namespace
  2. create with config file
  kubectl apply -f <FILENAME> --namespace=<NAMESPACE>
  (or include directly in config file metadata)
why?
  - group resources in Namespaces to get better overview of resources
  - avoid conflicts between teams
  - resource sharing (dev and staging, blue/green prod)
  - access and resource limits (CPU, RAM, Storage)
considerations:
  each NS needs own configMap & secrets
  services can be shared across NS
  volumes & nodes can't be created within NS
  can change the default NS w kubens

Service is abstraction layer that has IP address
Services can have multiple ports, but they have to be named in this case
Services types:
  - ClusterIP: default type
  - Headless: set 'clusterIP: None' (no service IP given, meaning that client will talk directly to Pod IP instead, useful when need to talk to specific Pods that differ because of state for eg)
  - NodePort: accessible from outside cluster using fixed port on each Worker node (range 30.000 - 32.767), however not secure
  - LoadBalancer: cluster becomes accessible using cloud providers native load balancer (extension and more secure alternative to NodePort which should only be used for quick testing)

Ingress
  preferred alternative to external service
  routing rules to map to service name and port
  domain name needs to be valid and based on IP address of node entry point
  need to install Ingress controller to evaliate all rules
  default backend if no service mapping found -> can create service with name 'default-http-backend' to handle such cases port 80
  can define multiple paths for same host
  can have multiple hosts with 1 path, each host representing a subdomain
  can configure https by importing tls certificate as secret within same namespace
  
Volumes
  persist data
  need to decide what type of storage is needed and manage it yourself
  not namespaced, accessible from everywhere in cluster
  provisioned by admin
  application needs to claim volume storage via Persistent Volume Claim (pvc) - both claim and pod claiming need to be in same namespace
  can create Storage Class to provision Persistent Volumes dynamically (abstracts underlying storage provider)
  
