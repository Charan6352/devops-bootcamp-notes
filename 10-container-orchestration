CONTAINER ORCHESTRATION w KUBERNETES

deploy more complex apps under microservices architecture (multiple containers)
- high availability/no downtime
- scalability/high performance
- disaster recovery/backup and restore

K8s components:
1. Node - physical or virtual server
2. Pod - abstraction over container (smallest unit of K8s)
  each Pod gets its own IP address
  Pods are ephemeral (can die easily), IP address recreated as new Pod recreated
3. Service - permanent IP address that can be attached to Pod, also acts as load balancer between Pods
4. Ingress - forwarding from request to Service (allows display dns in url)
5. ConfigMap - external config of app
6. Secret - used to store secret data, base64 encoded
7. Volumes - persists data
8. Deployment - blueprint for Pods (number of replicas) - abstraction layer over Pods
10. StatefulSet - Deployment for stateful apps or DBs
11. Replicaset - abstraction layer between pods and deployments (manages replicas of pods)
12. DaemonSet - runs on every worker node 
13. CRD - Custom Resource Definition

K8s architecture:
  each worker node has mutliple pods in it
  3 processes must be installed on every node:
    - container runtime (docker, container d ...)
    - Kubelet - interacts with both container and node
    - Kube proxy - forwards request from pods
  master nodes have 4 processes running:
    - api server - gateway & auth
    - scheduler - schedules pods across nodes
    - controller manager - detects state changes (eg crashing pods) and tries recover cluster state
    - etcd - key value store of cluster state
  prod cluster setup: multiple master and worker nodes

Minikube - for testing cluster setup on local: master & worker processes run on 1 node
  
Kubectl - cmd line tool for K8s: talk to API server
  kubectl get nodes
  kubectl get pod
  kubectl get pod -o wide (display more info for pod like IP address)
  kubectl get deployment
  kubectl get services
  kubectl create deployment NAME --image=image
  kubectl edit deployment NAME
  kubectl logs NAME
  kubectl describe pod NAME
  kubectl exec -it NAME -- bin/bash
  kubctl delete deployment NAME
  kubectl apply -f FILENAME (takes config file and exec what is in file, can be used to create edit delete)

K8s config file
  3 parts:
    1. metadata
    2. specification
    3. status (auto generated by K8s that checks diff to update state if applicable)
  store file w code
  pod has own config inside config
  connect deployment to pods, deployment to services using labels & selectors
  need to config ports for services (targetPort = container port that service wants to connect to)

Namespaces - organise resources
4 namespaces by default:
  - kube-system - system processes (DONT modify)
  - kube-public - configmap containing cluster info
  - kube-node-lease - heartbeat of nodes for availability
  - default - resources you create if haven't specified custom namespace
create namespaces options:
  1. kubectl create namespace <NAME>
  kubectl get namespace
  2. create with config file
  kubectl apply -f <FILENAME> --namespace=<NAMESPACE>
  (or include directly in config file metadata)
why?
  - group resources in Namespaces to get better overview of resources
  - avoid conflicts between teams
  - resource sharing (dev and staging, blue/green prod)
  - access and resource limits (CPU, RAM, Storage)
considerations:
  each NS needs own configMap & secrets
  services can be shared across NS
  volumes & nodes can't be created within NS
  can change the default NS w kubens

Service is abstraction layer that has IP address
Services can have multiple ports, but they have to be named in this case
Services types:
  - ClusterIP: default type
  - Headless: set 'clusterIP: None' (no service IP given, meaning that client will talk directly to Pod IP instead, useful when need to talk to specific Pods that differ because of state for eg)
  - NodePort: accessible from outside cluster using fixed port on each Worker node (range 30.000 - 32.767), however not secure
  - LoadBalancer: cluster becomes accessible using cloud providers native load balancer (extension and more secure alternative to NodePort which should only be used for quick testing)

Ingress
  preferred alternative to external service
  routing rules to map to service name and port
  domain name needs to be valid and based on IP address of node entry point
  need to install Ingress controller to evaliate all rules
  default backend if no service mapping found -> can create service with name 'default-http-backend' to handle such cases port 80
  can define multiple paths for same host
  can have multiple hosts with 1 path, each host representing a subdomain
  can configure https by importing tls certificate as secret within same namespace
  
Volumes
  persist data
  need to decide what type of storage is needed and manage it yourself
  not namespaced, accessible from everywhere in cluster
  provisioned by admin
  application needs to claim volume storage via Persistent Volume Claim (pvc) - both claim and pod claiming need to be in same namespace
  can create Storage Class to provision Persistent Volumes dynamically (abstracts underlying storage provider)
ConfigMap & Secret volumes ( = local volume types)
  can create individual key-value pairs - as env vars
  or mount files - mount as volume types
  1) mount volume into pods 2) mount volume into container (mountPath, path depends on type app that is mounted)
  
StatefulSet = deploying stateful apps
  persistent id for each pod
  only master pod allowed to write data, all other worker pods can only read
  each pod has own storage (for PV use remote storage), continuously sync data between pods
  each new pod clones data from previous up-to-date pod
  each pod gets own fixed DNS endpoint
  
  
Managed Kubernetes Services
  cluster setup done automatically for you, just need to specify number worker nodes need (saves effort however harder to migrate due to vendor lock-in) - out of the box node setup, storage, load balancing
  choose regions to setup closest to users
  can automate provisioning of cluster as many providers integrate with tools like Terraform
  
Helm - package manager for K8s
  Help Charts - pkg YAML files & distribute them in public + private repos to be shared
  can find deployments w Helm
    helm search repo <keyword>
    OR browse Helm Hub
  templating engine: define common blueprint and replace dynamic values (useful for deployments and across environments)
  cmd:
    helm search repo <keyword>
    help repo add <keyword>
    helm install <pod_name> --values <values_file> <helm_chart>
    helm uninstall <helm_chart>
  
  Pull from private Docker repo
    1. create secret component w creds for Docker registry - type dockerconfigjson
      kubectl create secret docker-registry <secret_name> --docker-server=<registry_url> --docker-username=<username> --docker-password=<password> 
      (only use above cmd for 1 secret, otherwise use 2-step docker login + secret config file)
    2. config deployment to use secret - imagePullSecrets
      force to pull Docker img even if already exists locally - imagePullPolicy: Always
    secret must be in same namespace as the deployment
  
  Operators
    mainly for stateful apps
    custom control loop mechanism
    custom K8s components 
    automatically manage full lifecycle of stateful apps
    those with domain specific knowledge create operator for that purpose
    
    
    
